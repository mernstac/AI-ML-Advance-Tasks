# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ETNzXBe3-eUD2ViLLuTMmOMwyiWKS9a2
"""

# Install required packages.

!pip install streamlit pypdf faiss-cpu sentence-transformers transformers torch
!npm install -g localtunnel

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import faiss
# import numpy as np
# from pypdf import PdfReader
# from sentence_transformers import SentenceTransformer
# from transformers import pipeline
# 
# # --- Load Models ---
# @st.cache_resource
# def load_models():
#     embedder = SentenceTransformer("all-MiniLM-L6-v2")
#     generator = pipeline("text2text-generation", model="google/flan-t5-base")
#     return embedder, generator
# 
# embedder, generator = load_models()
# 
# def chunk_text(text, chunk_size=500, overlap=50):
#     chunks = []
#     start = 0
#     while start < len(text):
#         end = start + chunk_size
#         chunks.append(text[start:end])
#         start = end - overlap
#     return chunks
# 
# st.title("ðŸ“„ PDF AI Assistant")
# 
# # Sidebar for uploads
# with st.sidebar:
#     uploaded_files = st.file_uploader("Upload PDFs", type="pdf", accept_multiple_files=True)
#     process = st.button("Index Documents")
# 
# if "index" not in st.session_state:
#     st.session_state.index = None
#     st.session_state.chunks = []
#     st.session_state.messages = []
# 
# if uploaded_files and process:
#     all_chunks = []
#     for f in uploaded_files:
#         reader = PdfReader(f)
#         for page in reader.pages:
#             all_chunks.extend(chunk_text(page.extract_text() or ""))
# 
#     embeddings = embedder.encode(all_chunks).astype("float32")
#     index = faiss.IndexFlatL2(embeddings.shape[1])
#     index.add(embeddings)
# 
#     st.session_state.index = index
#     st.session_state.chunks = all_chunks
#     st.success("Ready!")
# 
# # Chat
# for msg in st.session_state.messages:
#     with st.chat_message(msg["role"]): st.write(msg["content"])
# 
# if prompt := st.chat_input():
#     st.session_state.messages.append({"role": "user", "content": prompt})
#     with st.chat_message("user"): st.write(prompt)
# 
#     if st.session_state.index:
#         q_emb = embedder.encode([prompt]).astype("float32")
#         _, indices = st.session_state.index.search(q_emb, k=3)
#         context = "\n".join([st.session_state.chunks[i] for i in indices[0]])
# 
#         res = generator(f"Context: {context}\nQuestion: {prompt}")[0]['generated_text']
#         st.session_state.messages.append({"role": "assistant", "content": res})
#         with st.chat_message("assistant"): st.write(res)

# 1. Get your IP (You will need to paste this into the tunnel website)
import urllib
print("Your Password/Tunnel IP is:", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip())

# 2. Start the app
!streamlit run app.py & npx localtunnel --port 8501